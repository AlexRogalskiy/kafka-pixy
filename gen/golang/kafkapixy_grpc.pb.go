// Code generated by protoc-gen-go-grpc. DO NOT EDIT.

package golang

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.32.0 or later.
const _ = grpc.SupportPackageIsVersion7

// KafkaPixyClient is the client API for KafkaPixy service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type KafkaPixyClient interface {
	// Produce writes a message to a Kafka topic.
	//
	// If ProdReq.async_mode is false (default value) then the request will
	// block until the message is written to all ISR. In this case the respose
	// will contain the partition and offset of the message. This has to be
	// used to achive at-least-once deliverability guarantee.
	// If ProdReq.async_mode is true, then Kafka-Pixy returns immediately after
	// it gets the request and performs write on the backgroud. This mode
	// ensures highest throughput but messages can be lost, e.g. if the host
	// crashes before Kafka-Pixy has a chance to complete write.
	//
	// Hash of ProdReq.key_value is used to determine a partition that the
	// message should be written to. If you want a message to go to an random
	// partition then set ProdReq.key_undefined to true. Note that if both
	// ProdReq.key_undefined and ProdReq.key_value are left default, which is
	// empty string and false respectively, then messages will be consitently
	// written to a partiticular partition selected by the hash of an empty
	// string.
	//
	// gRPC error codes:
	//  * Invalid Argument (3): see the status description for details;
	//  * Internal (13): see the status description and logs for details;
	//  * Unavailable (14): the service is shutting down.
	Produce(ctx context.Context, in *ProdRq, opts ...grpc.CallOption) (*ProdRs, error)
	// Consume reads a message from a topic and optionally acknowledges a
	// message previously consumed from the same topic.
	//
	// Requests are performed in long polling fation, that is if all available
	// messages have been consumed then the request will block for
	// config.yaml:proxies.<cluster>.consumer.long_polling_timeout waiting for
	// new messages. If no new messages is produced while waiting the request
	// will return gRPC error with 408 status code.
	//
	// To consume the first message set ConsNAckReq.no_ack to true, since there
	// is no message to acknowledge at this point. In the second and all
	// subsequent calls of the method set ConsNAckReq.ack_partition and
	// ConsNAckReq.ack_offset to the respective values of ConsRes returned by
	// the previous method call. To acknowledge the last consumed message before
	// teminating the application call Ack method.
	//
	// If a message is not acknowledged within
	// config.yaml:proxies.<cluster>.consumer.ack_timeout the it will be returned
	// by Kafka-Pixy in ConsRes again possibly to another application.
	//
	// If at-least-once delivery guarantee and retries are not desirable, then
	// you can set ConsNAckReq.auto_ack to true and Kafka-Pixy will acknowledge
	// messages automatically before returning them in ConsRes.
	//
	// gRPC error codes:
	//  * Not Found (5): It just means that all message has been consumed and
	//    the long polling timeout has elaspsed. Just keep calling this method
	//    in a loop;
	//  * Resource Exhausted (8): too many consume requests. Either reduce the
	//    number of consuming threads or increase
	//    config.yaml:proxies.<cluster>.consumer.channel_buffer_size;
	//  * Invalid Argument (3): see the status description for details;
	//  * Internal (13): see the status description and logs for details;
	//  * Unavailable (14): the service is shutting down.
	ConsumeNAck(ctx context.Context, in *ConsNAckRq, opts ...grpc.CallOption) (*ConsRs, error)
	// Ack acknowledges a message earlier consumed from a topic.
	//
	// This method is provided solely to acknowledge the last consumed message
	// before the application terminates. In all other cases ConsumeNAck should
	// be used.
	//
	// gRPC error codes:
	//  * Invalid Argument (3): see the status description for details;
	//  * Internal (13): see the status description and logs for details;
	Ack(ctx context.Context, in *AckRq, opts ...grpc.CallOption) (*AckRs, error)
	// Fetches partition offsets for the specified topic and group
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on offset request
	//  * NotFound (5): If the group and or topic does not exist
	GetOffsets(ctx context.Context, in *GetOffsetsRq, opts ...grpc.CallOption) (*GetOffsetsRs, error)
	// Sets partition offsets for the specified topic and group.
	// NOTE: Although the request accepts the PartitionOffset object i
	// only 'Partition', 'Offset' and 'Metadata' are set by this method
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on offset request
	//  * NotFound (5): If the group and or topic does not exist
	SetOffsets(ctx context.Context, in *SetOffsetsRq, opts ...grpc.CallOption) (*SetOffsetsRs, error)
	// Lists all topics and metadata with optional metadata for the partitions of the topic
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on request
	ListTopics(ctx context.Context, in *ListTopicRq, opts ...grpc.CallOption) (*ListTopicRs, error)
	// Lists all consumers of a topic
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on request
	ListConsumers(ctx context.Context, in *ListConsumersRq, opts ...grpc.CallOption) (*ListConsumersRs, error)
	// Fetches topic metadata and optional metadata for the partitions of the topic
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on request
	//  * NotFound (5): If the topic does not exist
	GetTopicMetadata(ctx context.Context, in *GetTopicMetadataRq, opts ...grpc.CallOption) (*GetTopicMetadataRs, error)
}

type kafkaPixyClient struct {
	cc grpc.ClientConnInterface
}

func NewKafkaPixyClient(cc grpc.ClientConnInterface) KafkaPixyClient {
	return &kafkaPixyClient{cc}
}

func (c *kafkaPixyClient) Produce(ctx context.Context, in *ProdRq, opts ...grpc.CallOption) (*ProdRs, error) {
	out := new(ProdRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/Produce", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) ConsumeNAck(ctx context.Context, in *ConsNAckRq, opts ...grpc.CallOption) (*ConsRs, error) {
	out := new(ConsRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/ConsumeNAck", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) Ack(ctx context.Context, in *AckRq, opts ...grpc.CallOption) (*AckRs, error) {
	out := new(AckRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/Ack", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) GetOffsets(ctx context.Context, in *GetOffsetsRq, opts ...grpc.CallOption) (*GetOffsetsRs, error) {
	out := new(GetOffsetsRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/GetOffsets", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) SetOffsets(ctx context.Context, in *SetOffsetsRq, opts ...grpc.CallOption) (*SetOffsetsRs, error) {
	out := new(SetOffsetsRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/SetOffsets", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) ListTopics(ctx context.Context, in *ListTopicRq, opts ...grpc.CallOption) (*ListTopicRs, error) {
	out := new(ListTopicRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/ListTopics", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) ListConsumers(ctx context.Context, in *ListConsumersRq, opts ...grpc.CallOption) (*ListConsumersRs, error) {
	out := new(ListConsumersRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/ListConsumers", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) GetTopicMetadata(ctx context.Context, in *GetTopicMetadataRq, opts ...grpc.CallOption) (*GetTopicMetadataRs, error) {
	out := new(GetTopicMetadataRs)
	err := c.cc.Invoke(ctx, "/KafkaPixy/GetTopicMetadata", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// KafkaPixyServer is the server API for KafkaPixy service.
// All implementations must embed UnimplementedKafkaPixyServer
// for forward compatibility
type KafkaPixyServer interface {
	// Produce writes a message to a Kafka topic.
	//
	// If ProdReq.async_mode is false (default value) then the request will
	// block until the message is written to all ISR. In this case the respose
	// will contain the partition and offset of the message. This has to be
	// used to achive at-least-once deliverability guarantee.
	// If ProdReq.async_mode is true, then Kafka-Pixy returns immediately after
	// it gets the request and performs write on the backgroud. This mode
	// ensures highest throughput but messages can be lost, e.g. if the host
	// crashes before Kafka-Pixy has a chance to complete write.
	//
	// Hash of ProdReq.key_value is used to determine a partition that the
	// message should be written to. If you want a message to go to an random
	// partition then set ProdReq.key_undefined to true. Note that if both
	// ProdReq.key_undefined and ProdReq.key_value are left default, which is
	// empty string and false respectively, then messages will be consitently
	// written to a partiticular partition selected by the hash of an empty
	// string.
	//
	// gRPC error codes:
	//  * Invalid Argument (3): see the status description for details;
	//  * Internal (13): see the status description and logs for details;
	//  * Unavailable (14): the service is shutting down.
	Produce(context.Context, *ProdRq) (*ProdRs, error)
	// Consume reads a message from a topic and optionally acknowledges a
	// message previously consumed from the same topic.
	//
	// Requests are performed in long polling fation, that is if all available
	// messages have been consumed then the request will block for
	// config.yaml:proxies.<cluster>.consumer.long_polling_timeout waiting for
	// new messages. If no new messages is produced while waiting the request
	// will return gRPC error with 408 status code.
	//
	// To consume the first message set ConsNAckReq.no_ack to true, since there
	// is no message to acknowledge at this point. In the second and all
	// subsequent calls of the method set ConsNAckReq.ack_partition and
	// ConsNAckReq.ack_offset to the respective values of ConsRes returned by
	// the previous method call. To acknowledge the last consumed message before
	// teminating the application call Ack method.
	//
	// If a message is not acknowledged within
	// config.yaml:proxies.<cluster>.consumer.ack_timeout the it will be returned
	// by Kafka-Pixy in ConsRes again possibly to another application.
	//
	// If at-least-once delivery guarantee and retries are not desirable, then
	// you can set ConsNAckReq.auto_ack to true and Kafka-Pixy will acknowledge
	// messages automatically before returning them in ConsRes.
	//
	// gRPC error codes:
	//  * Not Found (5): It just means that all message has been consumed and
	//    the long polling timeout has elaspsed. Just keep calling this method
	//    in a loop;
	//  * Resource Exhausted (8): too many consume requests. Either reduce the
	//    number of consuming threads or increase
	//    config.yaml:proxies.<cluster>.consumer.channel_buffer_size;
	//  * Invalid Argument (3): see the status description for details;
	//  * Internal (13): see the status description and logs for details;
	//  * Unavailable (14): the service is shutting down.
	ConsumeNAck(context.Context, *ConsNAckRq) (*ConsRs, error)
	// Ack acknowledges a message earlier consumed from a topic.
	//
	// This method is provided solely to acknowledge the last consumed message
	// before the application terminates. In all other cases ConsumeNAck should
	// be used.
	//
	// gRPC error codes:
	//  * Invalid Argument (3): see the status description for details;
	//  * Internal (13): see the status description and logs for details;
	Ack(context.Context, *AckRq) (*AckRs, error)
	// Fetches partition offsets for the specified topic and group
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on offset request
	//  * NotFound (5): If the group and or topic does not exist
	GetOffsets(context.Context, *GetOffsetsRq) (*GetOffsetsRs, error)
	// Sets partition offsets for the specified topic and group.
	// NOTE: Although the request accepts the PartitionOffset object i
	// only 'Partition', 'Offset' and 'Metadata' are set by this method
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on offset request
	//  * NotFound (5): If the group and or topic does not exist
	SetOffsets(context.Context, *SetOffsetsRq) (*SetOffsetsRs, error)
	// Lists all topics and metadata with optional metadata for the partitions of the topic
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on request
	ListTopics(context.Context, *ListTopicRq) (*ListTopicRs, error)
	// Lists all consumers of a topic
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on request
	ListConsumers(context.Context, *ListConsumersRq) (*ListConsumersRs, error)
	// Fetches topic metadata and optional metadata for the partitions of the topic
	//
	// gRPC error codes:
	//  * Invalid Argument (3): If unable to find the cluster named in the request
	//  * Internal (13): If Kafka returns an error on request
	//  * NotFound (5): If the topic does not exist
	GetTopicMetadata(context.Context, *GetTopicMetadataRq) (*GetTopicMetadataRs, error)
	mustEmbedUnimplementedKafkaPixyServer()
}

// UnimplementedKafkaPixyServer must be embedded to have forward compatible implementations.
type UnimplementedKafkaPixyServer struct {
}

func (UnimplementedKafkaPixyServer) Produce(context.Context, *ProdRq) (*ProdRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Produce not implemented")
}
func (UnimplementedKafkaPixyServer) ConsumeNAck(context.Context, *ConsNAckRq) (*ConsRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ConsumeNAck not implemented")
}
func (UnimplementedKafkaPixyServer) Ack(context.Context, *AckRq) (*AckRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Ack not implemented")
}
func (UnimplementedKafkaPixyServer) GetOffsets(context.Context, *GetOffsetsRq) (*GetOffsetsRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GetOffsets not implemented")
}
func (UnimplementedKafkaPixyServer) SetOffsets(context.Context, *SetOffsetsRq) (*SetOffsetsRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method SetOffsets not implemented")
}
func (UnimplementedKafkaPixyServer) ListTopics(context.Context, *ListTopicRq) (*ListTopicRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ListTopics not implemented")
}
func (UnimplementedKafkaPixyServer) ListConsumers(context.Context, *ListConsumersRq) (*ListConsumersRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ListConsumers not implemented")
}
func (UnimplementedKafkaPixyServer) GetTopicMetadata(context.Context, *GetTopicMetadataRq) (*GetTopicMetadataRs, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GetTopicMetadata not implemented")
}
func (UnimplementedKafkaPixyServer) mustEmbedUnimplementedKafkaPixyServer() {}

// UnsafeKafkaPixyServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to KafkaPixyServer will
// result in compilation errors.
type UnsafeKafkaPixyServer interface {
	mustEmbedUnimplementedKafkaPixyServer()
}

func RegisterKafkaPixyServer(s grpc.ServiceRegistrar, srv KafkaPixyServer) {
	s.RegisterService(&KafkaPixy_ServiceDesc, srv)
}

func _KafkaPixy_Produce_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ProdRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).Produce(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/Produce",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).Produce(ctx, req.(*ProdRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_ConsumeNAck_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ConsNAckRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).ConsumeNAck(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/ConsumeNAck",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).ConsumeNAck(ctx, req.(*ConsNAckRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_Ack_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(AckRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).Ack(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/Ack",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).Ack(ctx, req.(*AckRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_GetOffsets_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetOffsetsRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).GetOffsets(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/GetOffsets",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).GetOffsets(ctx, req.(*GetOffsetsRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_SetOffsets_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SetOffsetsRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).SetOffsets(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/SetOffsets",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).SetOffsets(ctx, req.(*SetOffsetsRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_ListTopics_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListTopicRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).ListTopics(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/ListTopics",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).ListTopics(ctx, req.(*ListTopicRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_ListConsumers_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListConsumersRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).ListConsumers(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/ListConsumers",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).ListConsumers(ctx, req.(*ListConsumersRq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_GetTopicMetadata_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetTopicMetadataRq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).GetTopicMetadata(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/GetTopicMetadata",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).GetTopicMetadata(ctx, req.(*GetTopicMetadataRq))
	}
	return interceptor(ctx, in, info, handler)
}

// KafkaPixy_ServiceDesc is the grpc.ServiceDesc for KafkaPixy service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var KafkaPixy_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "KafkaPixy",
	HandlerType: (*KafkaPixyServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Produce",
			Handler:    _KafkaPixy_Produce_Handler,
		},
		{
			MethodName: "ConsumeNAck",
			Handler:    _KafkaPixy_ConsumeNAck_Handler,
		},
		{
			MethodName: "Ack",
			Handler:    _KafkaPixy_Ack_Handler,
		},
		{
			MethodName: "GetOffsets",
			Handler:    _KafkaPixy_GetOffsets_Handler,
		},
		{
			MethodName: "SetOffsets",
			Handler:    _KafkaPixy_SetOffsets_Handler,
		},
		{
			MethodName: "ListTopics",
			Handler:    _KafkaPixy_ListTopics_Handler,
		},
		{
			MethodName: "ListConsumers",
			Handler:    _KafkaPixy_ListConsumers_Handler,
		},
		{
			MethodName: "GetTopicMetadata",
			Handler:    _KafkaPixy_GetTopicMetadata_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "kafkapixy.proto",
}
