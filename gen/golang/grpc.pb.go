// Code generated by protoc-gen-go.
// source: grpc.proto
// DO NOT EDIT!

/*
Package pb is a generated protocol buffer package.

It is generated from these files:
	grpc.proto

It has these top-level messages:
	ProdReq
	ProdRes
	ConsNAckReq
	ConsRes
	AckReq
	AckRes
*/
package pb

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type ProdReq struct {
	// Name of a proxy (Kafka cluster) to operate on. Default proxy is used by
	// default.
	Proxy string `protobuf:"bytes,1,opt,name=proxy" json:"proxy,omitempty"`
	// Name of a topic to produce to.
	Topic string `protobuf:"bytes,2,opt,name=topic" json:"topic,omitempty"`
	// Hash of the key is used to determine the partition to produce to. By
	// default it is an empty array which is a valid key, unless key_undefined
	// is set to true and then a random partition is selected.
	KeyValue []byte `protobuf:"bytes,3,opt,name=key_value,json=keyValue,proto3" json:"key_value,omitempty"`
	// If true then the message is written to a random partition, otherwise
	// hash of key_value is used to determine the partition.
	KeyUndefined bool `protobuf:"varint,4,opt,name=key_undefined,json=keyUndefined" json:"key_undefined,omitempty"`
	// Message body.
	Message []byte `protobuf:"bytes,5,opt,name=message,proto3" json:"message,omitempty"`
	// If true then the method returns immediately after Kafka-Pixy get the
	// produce request, and the message is written to Kafka asynchronously.
	// In that case partition and offset returned in response should be ignored.
	// If false (by default), then a response is returned after the message is
	// written to all ISR and response provides partition+offset where it was
	// actually written.
	AsyncMode bool `protobuf:"varint,6,opt,name=async_mode,json=asyncMode" json:"async_mode,omitempty"`
}

func (m *ProdReq) Reset()                    { *m = ProdReq{} }
func (m *ProdReq) String() string            { return proto.CompactTextString(m) }
func (*ProdReq) ProtoMessage()               {}
func (*ProdReq) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func (m *ProdReq) GetProxy() string {
	if m != nil {
		return m.Proxy
	}
	return ""
}

func (m *ProdReq) GetTopic() string {
	if m != nil {
		return m.Topic
	}
	return ""
}

func (m *ProdReq) GetKeyValue() []byte {
	if m != nil {
		return m.KeyValue
	}
	return nil
}

func (m *ProdReq) GetKeyUndefined() bool {
	if m != nil {
		return m.KeyUndefined
	}
	return false
}

func (m *ProdReq) GetMessage() []byte {
	if m != nil {
		return m.Message
	}
	return nil
}

func (m *ProdReq) GetAsyncMode() bool {
	if m != nil {
		return m.AsyncMode
	}
	return false
}

type ProdRes struct {
	// Partition the message was written to. The value only makes sense if
	// ProdReq.async_mode was false.
	Partition int32 `protobuf:"varint,1,opt,name=partition" json:"partition,omitempty"`
	// Offset the message was written to. The value only makes sense if
	// ProdReq.async_mode was false.
	Offset int64 `protobuf:"varint,2,opt,name=offset" json:"offset,omitempty"`
}

func (m *ProdRes) Reset()                    { *m = ProdRes{} }
func (m *ProdRes) String() string            { return proto.CompactTextString(m) }
func (*ProdRes) ProtoMessage()               {}
func (*ProdRes) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }

func (m *ProdRes) GetPartition() int32 {
	if m != nil {
		return m.Partition
	}
	return 0
}

func (m *ProdRes) GetOffset() int64 {
	if m != nil {
		return m.Offset
	}
	return 0
}

type ConsNAckReq struct {
	// Name of a proxy (Kafka cluster) to operate on. Default proxy is used by
	// default.
	Proxy string `protobuf:"bytes,1,opt,name=proxy" json:"proxy,omitempty"`
	// Name of a topic to produce to.
	Topic string `protobuf:"bytes,2,opt,name=topic" json:"topic,omitempty"`
	// Name of a consumer group.
	Group string `protobuf:"bytes,3,opt,name=group" json:"group,omitempty"`
	// If true then no message is acknowledged by the request.
	NoAck bool `protobuf:"varint,4,opt,name=no_ack,json=noAck" json:"no_ack,omitempty"`
	// If true and no_ack is false then the message returned by the requests is
	// automatically acknowledged by Kafka-Pixy before the request completes.
	AutoAck bool `protobuf:"varint,5,opt,name=auto_ack,json=autoAck" json:"auto_ack,omitempty"`
	// If both no_ack and auto_ack are false (by default), then ack_partition
	// and ack_offset along with proxy+group+topic determine the message that
	// should be acknowledged by the request.
	AckPartition int32 `protobuf:"varint,6,opt,name=ack_partition,json=ackPartition" json:"ack_partition,omitempty"`
	AckOffset    int64 `protobuf:"varint,7,opt,name=ack_offset,json=ackOffset" json:"ack_offset,omitempty"`
}

func (m *ConsNAckReq) Reset()                    { *m = ConsNAckReq{} }
func (m *ConsNAckReq) String() string            { return proto.CompactTextString(m) }
func (*ConsNAckReq) ProtoMessage()               {}
func (*ConsNAckReq) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{2} }

func (m *ConsNAckReq) GetProxy() string {
	if m != nil {
		return m.Proxy
	}
	return ""
}

func (m *ConsNAckReq) GetTopic() string {
	if m != nil {
		return m.Topic
	}
	return ""
}

func (m *ConsNAckReq) GetGroup() string {
	if m != nil {
		return m.Group
	}
	return ""
}

func (m *ConsNAckReq) GetNoAck() bool {
	if m != nil {
		return m.NoAck
	}
	return false
}

func (m *ConsNAckReq) GetAutoAck() bool {
	if m != nil {
		return m.AutoAck
	}
	return false
}

func (m *ConsNAckReq) GetAckPartition() int32 {
	if m != nil {
		return m.AckPartition
	}
	return 0
}

func (m *ConsNAckReq) GetAckOffset() int64 {
	if m != nil {
		return m.AckOffset
	}
	return 0
}

type ConsRes struct {
	// Partition the message was read from.
	Partition int32 `protobuf:"varint,1,opt,name=partition" json:"partition,omitempty"`
	// Offset of the read message in the partition.
	Offset int64 `protobuf:"varint,2,opt,name=offset" json:"offset,omitempty"`
	// Key that was used to produce the message, unless key_undefined is true,
	// then it is undefined.
	KeyValue []byte `protobuf:"bytes,3,opt,name=key_value,json=keyValue,proto3" json:"key_value,omitempty"`
	// If true then the message was produced to a random partition.
	KeyUndefined bool `protobuf:"varint,4,opt,name=key_undefined,json=keyUndefined" json:"key_undefined,omitempty"`
	// Message body
	Message []byte `protobuf:"bytes,5,opt,name=message,proto3" json:"message,omitempty"`
}

func (m *ConsRes) Reset()                    { *m = ConsRes{} }
func (m *ConsRes) String() string            { return proto.CompactTextString(m) }
func (*ConsRes) ProtoMessage()               {}
func (*ConsRes) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{3} }

func (m *ConsRes) GetPartition() int32 {
	if m != nil {
		return m.Partition
	}
	return 0
}

func (m *ConsRes) GetOffset() int64 {
	if m != nil {
		return m.Offset
	}
	return 0
}

func (m *ConsRes) GetKeyValue() []byte {
	if m != nil {
		return m.KeyValue
	}
	return nil
}

func (m *ConsRes) GetKeyUndefined() bool {
	if m != nil {
		return m.KeyUndefined
	}
	return false
}

func (m *ConsRes) GetMessage() []byte {
	if m != nil {
		return m.Message
	}
	return nil
}

type AckReq struct {
	// Name of a proxy (Kafka cluster) to operate on. Default proxy is used by
	// default.
	Proxy string `protobuf:"bytes,1,opt,name=proxy" json:"proxy,omitempty"`
	// Name of a topic to produce to.
	Topic string `protobuf:"bytes,2,opt,name=topic" json:"topic,omitempty"`
	// Name of a consumer group.
	Group string `protobuf:"bytes,3,opt,name=group" json:"group,omitempty"`
	// Partition that the acknowledged message was consumed from.
	Partition int32 `protobuf:"varint,4,opt,name=partition" json:"partition,omitempty"`
	// Offset in the partition that the acknowledged message was consumed from.
	Offset int64 `protobuf:"varint,5,opt,name=offset" json:"offset,omitempty"`
}

func (m *AckReq) Reset()                    { *m = AckReq{} }
func (m *AckReq) String() string            { return proto.CompactTextString(m) }
func (*AckReq) ProtoMessage()               {}
func (*AckReq) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{4} }

func (m *AckReq) GetProxy() string {
	if m != nil {
		return m.Proxy
	}
	return ""
}

func (m *AckReq) GetTopic() string {
	if m != nil {
		return m.Topic
	}
	return ""
}

func (m *AckReq) GetGroup() string {
	if m != nil {
		return m.Group
	}
	return ""
}

func (m *AckReq) GetPartition() int32 {
	if m != nil {
		return m.Partition
	}
	return 0
}

func (m *AckReq) GetOffset() int64 {
	if m != nil {
		return m.Offset
	}
	return 0
}

type AckRes struct {
}

func (m *AckRes) Reset()                    { *m = AckRes{} }
func (m *AckRes) String() string            { return proto.CompactTextString(m) }
func (*AckRes) ProtoMessage()               {}
func (*AckRes) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{5} }

func init() {
	proto.RegisterType((*ProdReq)(nil), "ProdReq")
	proto.RegisterType((*ProdRes)(nil), "ProdRes")
	proto.RegisterType((*ConsNAckReq)(nil), "ConsNAckReq")
	proto.RegisterType((*ConsRes)(nil), "ConsRes")
	proto.RegisterType((*AckReq)(nil), "AckReq")
	proto.RegisterType((*AckRes)(nil), "AckRes")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for KafkaPixy service

type KafkaPixyClient interface {
	// Produce writes a message to a Kafka topic.
	//
	// If ProdReq.async_mode is false (default value) then the request will
	// block until the message is written to all ISR. In this case the respose
	// will contain the partition and offset of the message. This has to be
	// used to achive at-least-once deliverability guarantee.
	// If ProdReq.async_mode is true, then Kafka-Pixy returns immediately after
	// it gets the request and performs write on the backgroud. This mode
	// ensures highest throughput but messages can be lost, e.g. if the host
	// crashes before Kafka-Pixy has a chance to complete write.
	//
	// Hash of ProdReq.key_value is used to determine a partition that the
	// message should be written to. If you want a message to go to an random
	// partition then set ProdReq.key_undefined to true. Note that if both
	// ProdReq.key_undefined and ProdReq.key_value are left default, which is
	// empty string and false respectively, then messages will be consitently
	// written to a partiticular partition selected by the hash of an empty
	// string.
	//
	// gRPC error codes:
	//  * 3: invalid argument, see the status description for details;
	//  * 404: topic does not exist (if Kafka cluster is not configured to
	//         automatically create topics);
	//  * 500: internal error, see the status description and logs for details;
	Produce(ctx context.Context, in *ProdReq, opts ...grpc.CallOption) (*ProdRes, error)
	// Consume reads a message from a topic and optionally acknowledges a
	// message previously consumed from the same topic.
	//
	// Requests are performed in long polling fation, that is if all available
	// messages have been consumed then the request will block for
	// config.yaml:proxies.<proxy>.consumer.long_polling_timeout waiting for
	// new messages. If no new messages is produced while waiting the request
	// will return gRPC error with 408 status code.
	//
	// To consume the first message set ConsNAckReq.no_ack to true, since there
	// is no message to acknowledge at this point. In the second and all
	// subsequent calls of the method set ConsNAckReq.ack_partition and
	// ConsNAckReq.ack_offset to the respective values of ConsRes returned by
	// the previous method call. To acknowledge the last consumed message before
	// teminating the application call Ack method.
	//
	// If a message is not acknowledged within
	// config.yaml:proxies.<proxy>.consumer.ack_timeout the it will be returned
	// by Kafka-Pixy in ConsRes again possibly to another application.
	//
	// If at-least-once delivery guarantee and retries are not desirable, then
	// you can set ConsNAckReq.auto_ack to true and Kafka-Pixy will acknowledge
	// messages automatically before returning them in ConsRes.
	//
	// gRPC error codes:
	//  * 3: invalid argument, see the status description for details;
	//  * 408: long polling timeout. It just means that all message has been
	//         consumed. Just keep calling this method in a loop;
	//  * 429: too many consume requests. Either reduce the number of consuming
	//         threads or increase
	//         config.yaml:proxies.<proxy>.consumer.channel_buffer_size;
	//  * 500: internal error, see the status description and logs for details;
	ConsumeNAck(ctx context.Context, in *ConsNAckReq, opts ...grpc.CallOption) (*ConsRes, error)
	// Ack acknowledges a message earlier consumed from a topic.
	//
	// This method is provided solely to acknowledge the last consumed message
	// before the application terminates. In all other cases ConsumeNAck should
	// be used.
	//
	// gRPC error codes:
	//  * 3: invalid argument, see the status description for details;
	//  * 500: internal error, see the status description and logs for details;
	Ack(ctx context.Context, in *AckReq, opts ...grpc.CallOption) (*AckRes, error)
}

type kafkaPixyClient struct {
	cc *grpc.ClientConn
}

func NewKafkaPixyClient(cc *grpc.ClientConn) KafkaPixyClient {
	return &kafkaPixyClient{cc}
}

func (c *kafkaPixyClient) Produce(ctx context.Context, in *ProdReq, opts ...grpc.CallOption) (*ProdRes, error) {
	out := new(ProdRes)
	err := grpc.Invoke(ctx, "/KafkaPixy/Produce", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) ConsumeNAck(ctx context.Context, in *ConsNAckReq, opts ...grpc.CallOption) (*ConsRes, error) {
	out := new(ConsRes)
	err := grpc.Invoke(ctx, "/KafkaPixy/ConsumeNAck", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaPixyClient) Ack(ctx context.Context, in *AckReq, opts ...grpc.CallOption) (*AckRes, error) {
	out := new(AckRes)
	err := grpc.Invoke(ctx, "/KafkaPixy/Ack", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for KafkaPixy service

type KafkaPixyServer interface {
	// Produce writes a message to a Kafka topic.
	//
	// If ProdReq.async_mode is false (default value) then the request will
	// block until the message is written to all ISR. In this case the respose
	// will contain the partition and offset of the message. This has to be
	// used to achive at-least-once deliverability guarantee.
	// If ProdReq.async_mode is true, then Kafka-Pixy returns immediately after
	// it gets the request and performs write on the backgroud. This mode
	// ensures highest throughput but messages can be lost, e.g. if the host
	// crashes before Kafka-Pixy has a chance to complete write.
	//
	// Hash of ProdReq.key_value is used to determine a partition that the
	// message should be written to. If you want a message to go to an random
	// partition then set ProdReq.key_undefined to true. Note that if both
	// ProdReq.key_undefined and ProdReq.key_value are left default, which is
	// empty string and false respectively, then messages will be consitently
	// written to a partiticular partition selected by the hash of an empty
	// string.
	//
	// gRPC error codes:
	//  * 3: invalid argument, see the status description for details;
	//  * 404: topic does not exist (if Kafka cluster is not configured to
	//         automatically create topics);
	//  * 500: internal error, see the status description and logs for details;
	Produce(context.Context, *ProdReq) (*ProdRes, error)
	// Consume reads a message from a topic and optionally acknowledges a
	// message previously consumed from the same topic.
	//
	// Requests are performed in long polling fation, that is if all available
	// messages have been consumed then the request will block for
	// config.yaml:proxies.<proxy>.consumer.long_polling_timeout waiting for
	// new messages. If no new messages is produced while waiting the request
	// will return gRPC error with 408 status code.
	//
	// To consume the first message set ConsNAckReq.no_ack to true, since there
	// is no message to acknowledge at this point. In the second and all
	// subsequent calls of the method set ConsNAckReq.ack_partition and
	// ConsNAckReq.ack_offset to the respective values of ConsRes returned by
	// the previous method call. To acknowledge the last consumed message before
	// teminating the application call Ack method.
	//
	// If a message is not acknowledged within
	// config.yaml:proxies.<proxy>.consumer.ack_timeout the it will be returned
	// by Kafka-Pixy in ConsRes again possibly to another application.
	//
	// If at-least-once delivery guarantee and retries are not desirable, then
	// you can set ConsNAckReq.auto_ack to true and Kafka-Pixy will acknowledge
	// messages automatically before returning them in ConsRes.
	//
	// gRPC error codes:
	//  * 3: invalid argument, see the status description for details;
	//  * 408: long polling timeout. It just means that all message has been
	//         consumed. Just keep calling this method in a loop;
	//  * 429: too many consume requests. Either reduce the number of consuming
	//         threads or increase
	//         config.yaml:proxies.<proxy>.consumer.channel_buffer_size;
	//  * 500: internal error, see the status description and logs for details;
	ConsumeNAck(context.Context, *ConsNAckReq) (*ConsRes, error)
	// Ack acknowledges a message earlier consumed from a topic.
	//
	// This method is provided solely to acknowledge the last consumed message
	// before the application terminates. In all other cases ConsumeNAck should
	// be used.
	//
	// gRPC error codes:
	//  * 3: invalid argument, see the status description for details;
	//  * 500: internal error, see the status description and logs for details;
	Ack(context.Context, *AckReq) (*AckRes, error)
}

func RegisterKafkaPixyServer(s *grpc.Server, srv KafkaPixyServer) {
	s.RegisterService(&_KafkaPixy_serviceDesc, srv)
}

func _KafkaPixy_Produce_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ProdReq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).Produce(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/Produce",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).Produce(ctx, req.(*ProdReq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_ConsumeNAck_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ConsNAckReq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).ConsumeNAck(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/ConsumeNAck",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).ConsumeNAck(ctx, req.(*ConsNAckReq))
	}
	return interceptor(ctx, in, info, handler)
}

func _KafkaPixy_Ack_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(AckReq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaPixyServer).Ack(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/KafkaPixy/Ack",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaPixyServer).Ack(ctx, req.(*AckReq))
	}
	return interceptor(ctx, in, info, handler)
}

var _KafkaPixy_serviceDesc = grpc.ServiceDesc{
	ServiceName: "KafkaPixy",
	HandlerType: (*KafkaPixyServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Produce",
			Handler:    _KafkaPixy_Produce_Handler,
		},
		{
			MethodName: "ConsumeNAck",
			Handler:    _KafkaPixy_ConsumeNAck_Handler,
		},
		{
			MethodName: "Ack",
			Handler:    _KafkaPixy_Ack_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "grpc.proto",
}

func init() { proto.RegisterFile("grpc.proto", fileDescriptor0) }

var fileDescriptor0 = []byte{
	// 406 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x02, 0xff, 0xb4, 0x93, 0x4f, 0x8e, 0xd3, 0x30,
	0x18, 0xc5, 0xeb, 0xb6, 0xf9, 0xf7, 0x91, 0x6e, 0xac, 0x82, 0xd2, 0x02, 0xa2, 0x4a, 0x17, 0x74,
	0x95, 0x05, 0x1c, 0x00, 0x15, 0x96, 0x08, 0xa8, 0x22, 0xc1, 0x82, 0x4d, 0xe4, 0x3a, 0x4e, 0x15,
	0x99, 0xc6, 0x26, 0x4e, 0x50, 0xb3, 0xe3, 0x1e, 0x5c, 0x82, 0x4b, 0xcc, 0xbd, 0x46, 0x76, 0x9c,
	0xe9, 0x74, 0x31, 0x8b, 0x19, 0xcd, 0xec, 0xfc, 0xbe, 0x17, 0x4b, 0xef, 0xf7, 0xf9, 0x05, 0xe0,
	0x50, 0x4b, 0x9a, 0xc8, 0x5a, 0x34, 0x22, 0xfe, 0x8f, 0xc0, 0xdb, 0xd5, 0x22, 0x4f, 0xd9, 0x6f,
	0x3c, 0x07, 0x47, 0xd6, 0xe2, 0xd4, 0x45, 0x68, 0x85, 0x36, 0x41, 0xda, 0x0b, 0x3d, 0x6d, 0x84,
	0x2c, 0x69, 0x34, 0xee, 0xa7, 0x46, 0xe0, 0x97, 0x10, 0x70, 0xd6, 0x65, 0x7f, 0xc8, 0xaf, 0x96,
	0x45, 0x93, 0x15, 0xda, 0x84, 0xa9, 0xcf, 0x59, 0xf7, 0x43, 0x6b, 0xbc, 0x86, 0x99, 0x36, 0xdb,
	0x2a, 0x67, 0x45, 0x59, 0xb1, 0x3c, 0x9a, 0xae, 0xd0, 0xc6, 0x4f, 0x43, 0xce, 0xba, 0xef, 0xc3,
	0x0c, 0x47, 0xe0, 0x1d, 0x99, 0x52, 0xe4, 0xc0, 0x22, 0xc7, 0xdc, 0x1f, 0x24, 0x7e, 0x0d, 0x40,
	0x54, 0x57, 0xd1, 0xec, 0x28, 0x72, 0x16, 0xb9, 0xe6, 0x6e, 0x60, 0x26, 0x5f, 0x44, 0xce, 0xe2,
	0x0f, 0x43, 0x62, 0x85, 0x5f, 0x41, 0x20, 0x49, 0xdd, 0x94, 0x4d, 0x29, 0x2a, 0x93, 0xda, 0x49,
	0xcf, 0x03, 0xfc, 0x02, 0x5c, 0x51, 0x14, 0x8a, 0x35, 0x26, 0xfa, 0x24, 0xb5, 0x2a, 0xbe, 0x42,
	0xf0, 0xec, 0x93, 0xa8, 0xd4, 0xd7, 0x2d, 0xe5, 0xf7, 0xe5, 0x9e, 0x83, 0x73, 0xa8, 0x45, 0x2b,
	0x0d, 0x73, 0x90, 0xf6, 0x02, 0x3f, 0x07, 0xb7, 0x12, 0x19, 0xa1, 0xdc, 0x92, 0x3a, 0x95, 0xd8,
	0x52, 0x8e, 0x17, 0xe0, 0x93, 0xb6, 0xe9, 0x0d, 0xc7, 0x18, 0x9e, 0xd6, 0xda, 0x5a, 0xc3, 0x8c,
	0x50, 0x9e, 0x9d, 0xd3, 0xbb, 0x26, 0x7d, 0x48, 0x28, 0xdf, 0xdd, 0x00, 0xe8, 0x45, 0x50, 0x9e,
	0x59, 0x08, 0xcf, 0x40, 0x04, 0x84, 0xf2, 0x6f, 0x3d, 0xc7, 0x3f, 0x04, 0x9e, 0xe6, 0x78, 0xf0,
	0x26, 0x9e, 0xf2, 0x15, 0xe3, 0xbf, 0x08, 0xdc, 0x47, 0x5b, 0xf0, 0x05, 0xde, 0xf4, 0x6e, 0x3c,
	0xe7, 0xe2, 0xa1, 0x7d, 0x9b, 0x40, 0xbd, 0x93, 0x10, 0x7c, 0x26, 0x05, 0x27, 0xbb, 0xf2, 0xd4,
	0xe1, 0x37, 0x7d, 0x81, 0x5a, 0xca, 0xb0, 0x9f, 0xd8, 0xf2, 0x2f, 0x87, 0x93, 0x8a, 0x47, 0xf8,
	0x6d, 0xdf, 0x8f, 0xf6, 0xc8, 0x74, 0x45, 0x70, 0x98, 0xdc, 0x6a, 0xcb, 0xd2, 0x4f, 0xec, 0xce,
	0xe3, 0x11, 0x5e, 0xc0, 0x44, 0x7f, 0xe0, 0x25, 0xd6, 0xb3, 0x07, 0x15, 0x8f, 0x3e, 0x4e, 0x7f,
	0x8e, 0xe5, 0x7e, 0xef, 0x9a, 0xbf, 0xec, 0xfd, 0x75, 0x00, 0x00, 0x00, 0xff, 0xff, 0xdd, 0xc8,
	0x65, 0x82, 0x73, 0x03, 0x00, 0x00,
}
